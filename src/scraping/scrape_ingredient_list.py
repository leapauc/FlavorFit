"""
================================================================================
Scraper combin√© Marmiton + Ciqual (version headless)
================================================================================

üìå Objectif
-----------
Ce script combine deux t√¢ches principales :
1. **Scraping du site Marmiton.org** pour extraire la liste compl√®te des ingr√©dients.
2. **Scraping du site Ciqual (ANSES)** pour obtenir, pour chaque ingr√©dient,
   les principales valeurs nutritionnelles (√ânergie, Prot√©ines, Lipides, etc.).

Le tout s'ex√©cute de mani√®re automatis√©e et silencieuse (mode headless),
afin de g√©n√©rer un fichier CSV final regroupant l'ensemble des donn√©es.

--------------------------------------------------------------------------------
üß† Contexte
-----------
- **Marmiton.org** est un site de recettes de cuisine comportant une base
  d'ingr√©dients class√©s par ordre alphab√©tique.
- **Ciqual (anses.fr)** est une base de donn√©es nutritionnelles fran√ßaise
  recensant la composition alimentaire des produits.

L'objectif de ce script est de croiser ces deux sources :
> "Pour chaque ingr√©dient trouv√© sur Marmiton, obtenir ses valeurs nutritionnelles
   (kJ/100 g, prot√©ines, lipides, glucides, etc.) depuis la base Ciqual."

--------------------------------------------------------------------------------
üì¶ R√©sultat
-----------
Le script g√©n√®re un fichier CSV unique :
    ‚Üí `ingredients_marmiton_ciqual.csv`

Ce fichier contient les colonnes suivantes :
    - **Ingr√©dient**
    - **√ânergie (kJ/100g)**
    - **Prot√©ines (g/100g)**
    - **Lipides (g/100g)**
    - **Glucides (g/100g)**
    - **Sucres (g/100g)**
    - **Fibres (g/100g)**
    - **Sel (g/100g)**
    - **AG satur√©s (g/100g)**
    - **Cholest√©rol (mg/100g)**

--------------------------------------------------------------------------------
‚öôÔ∏è Pr√©requis techniques
------------------------
‚úÖ Biblioth√®ques Python :
    pip install requests beautifulsoup4 selenium pandas

‚úÖ Navigateur + driver Selenium :
    - Google Chrome + ChromeDriver (recommand√©)
      https://chromedriver.chromium.org/downloads
    - Firefox + GeckoDriver (alternative)
      https://github.com/mozilla/geckodriver/releases

‚úÖ Environnement :
    - Windows / macOS / Linux
    - Python 3.8+

--------------------------------------------------------------------------------
‚ö†Ô∏è Mentions l√©gales et √©thiques
-------------------------------
- Ce script est con√ßu √† des fins √©ducatives et de recherche.
- Respecte les conditions d'utilisation de Marmiton.org et Ciqual.anses.fr.
- √âvite les requ√™tes trop fr√©quentes (une pause `time.sleep` est incluse).
- Ne redistribue pas les donn√©es Ciqual sans autorisation.

--------------------------------------------------------------------------------
Auteur  : L√©a PAUCHOT + OpenAI
Version : 13 Novembre 2025
================================================================================
"""

# =====================================================
# üß© IMPORTS ET CONSTANTES
# =====================================================

import requests
from bs4 import BeautifulSoup
import string
import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from selenium.common.exceptions import StaleElementReferenceException


# =====================================================
# üîπ 1. SCRAPING MARMITON
# =====================================================

BASE_URL = "https://www.marmiton.org/recettes/index/ingredient/"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; IngredientScraper/1.0; +https://example.com)"
}


def get_ingredient_names(letter):
    """
    R√©cup√®re tous les noms d'ingr√©dients pour une lettre donn√©e sur Marmiton.

    Args:
        letter (str): Lettre de l'alphabet √† scraper (ex. 'a').

    Returns:
        list[str]: Liste des noms d'ingr√©dients trouv√©s.
    """
    ingredients = []
    page = 1

    while True:
        url = f"{BASE_URL}{letter}/{page}"
        response = requests.get(url, headers=HEADERS)
        if response.status_code != 200:
            break

        soup = BeautifulSoup(response.text, "html.parser")
        spans = soup.select("span.card-needed__name")
        if not spans:
            break

        for span in spans:
            ingredients.append(span.text.strip())

        print(f"[{letter.upper()}] Page {page} ‚Üí {len(spans)} ingr√©dients trouv√©s")
        page += 1
        time.sleep(0.5)

    return ingredients


def scrape_all_ingredients():
    """
    Scrape la liste compl√®te des ingr√©dients de A √† Z.

    Returns:
        list[str]: Liste de tous les ingr√©dients trouv√©s.
    """
    all_ingredients = []
    for letter in string.ascii_lowercase:
        all_ingredients.extend(get_ingredient_names(letter))
    return all_ingredients


# =====================================================
# üîπ 2. SCRAPING CIQUAL (√âTENDU)
# =====================================================

NUTRIENTS_TO_EXTRACT = {
    "Energie, N x facteur Jones, avec fibres": "Energie, N x facteur Jones, avec fibres (kJ/100 g)",
    "Prot√©ines, N x 6.25": "Prot√©ines, N x 6.25 (g/100 g)",
    "Lipides": "Lipides (g/100g)",
    "Glucides": "Glucides (g/100g)",
    "Sucres": "Sucres (g/100g)",
    "Fibres alimentaires": "Fibres (g/100g)",
    "Sel (NaCl)": "Sel chlorure de sodium (g/100 g)",
    "AG satur√©s": "AG satur√©s (g/100g)",
    "Cholest√©rol": "Cholest√©rol (mg/100g)"
}


def get_driver(headless=True):
    """
    Initialise le navigateur Selenium (mode headless par d√©faut).

    Args:
        headless (bool): Si True, ex√©cute le navigateur sans interface graphique.

    Returns:
        selenium.webdriver.Chrome: Navigateur pr√™t √† l‚Äôemploi.
    """
    options = Options()
    if headless:
        options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    return webdriver.Chrome(options=options)


def get_nutritional_values(driver, ingredient, max_retries=3):
    """
    Recherche un ingr√©dient sur Ciqual et r√©cup√®re ses valeurs nutritionnelles.
    Robuste face aux mises √† jour du DOM (StaleElementReferenceException).

    Args:
        driver (webdriver): Instance Selenium active.
        ingredient (str): Nom de l'ingr√©dient √† rechercher.
        max_retries (int): Nombre maximal de tentatives.

    Returns:
        dict: Dictionnaire {nom_nutriment: valeur ou None}.
    """
    data = {"Ingr√©dient": ingredient}
    for label in NUTRIENTS_TO_EXTRACT.values():
        data[label] = None

    for attempt in range(1, max_retries + 1):
        try:
            # Saisie dans le champ de recherche
            search_box = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.ID, "champ-recherche"))
            )
            search_box.clear()
            search_box.send_keys(ingredient)
            search_box.send_keys(Keys.RETURN)
            time.sleep(0.3)  # Laisser Angular mettre √† jour la page

            # Pour chaque nutriment, recherche et lecture directe
            for nutri_label, col_name in NUTRIENTS_TO_EXTRACT.items():
                try:
                    value_elem = WebDriverWait(driver, 5).until(
                        EC.presence_of_element_located(
                            (By.XPATH, f"//span[contains(text(), '{nutri_label}')]/ancestor::tr/td[2]")
                        )
                    )
                    # Lecture s√©curis√©e avec retry
                    for _ in range(3):
                        try:
                            data[col_name] = value_elem.text.strip()
                            break
                        except StaleElementReferenceException:
                            time.sleep(0.5)
                            value_elem = driver.find_element(
                                By.XPATH, f"//span[contains(text(), '{nutri_label}')]/ancestor::tr/td[2]"
                            )
                except (TimeoutException, NoSuchElementException):
                    data[col_name] = None

            return data

        except (TimeoutException, StaleElementReferenceException) as e:
            print(f"‚ö†Ô∏è Tentative {attempt}/{max_retries} √©chou√©e pour '{ingredient}' ({e.__class__.__name__})")
            time.sleep(0.1)
            driver.get("https://ciqual.anses.fr/")  # reload page
            continue

    print(f"‚ùå √âchec complet pour '{ingredient}' apr√®s {max_retries} tentatives.")
    return data


def scrape_ciqual_extended(ingredients, output_file="ingredients_marmiton_ciqual.csv", headless=True):
    """
    Scrape Ciqual pour obtenir les nutriments de chaque ingr√©dient.

    Args:
        ingredients (list[str]): Liste d'ingr√©dients √† interroger.
        output_file (str): Nom du fichier CSV final.
        headless (bool): Mode d‚Äôex√©cution sans interface graphique.

    Returns:
        pd.DataFrame: Donn√©es nutritionnelles compl√®tes.
    """
    driver = get_driver(headless=headless)
    driver.get("https://ciqual.anses.fr/")
    results = []

    for i, ing in enumerate(ingredients, start=1):
        print(f"({i}/{len(ingredients)}) Recherche : {ing}")
        nutri_data = get_nutritional_values(driver, ing)
        results.append(nutri_data)
        found = sum(v is not None for v in nutri_data.values()) - 1
        print(f"‚Üí {found} nutriments trouv√©s")
        time.sleep(0.5)

    driver.quit()
    df = pd.DataFrame(results)
    df.to_csv(output_file, index=False, encoding="utf-8")
    print(f"\n‚úÖ Donn√©es enregistr√©es dans : {output_file}")
    return df


# =====================================================
# üîπ 3. CHA√éNAGE AUTOMATIQUE
# =====================================================

if __name__ == "__main__":
    """
    Point d'entr√©e principal du script.

    √âtapes :
        1Ô∏è‚É£ Scraping complet des ingr√©dients Marmiton.
        2Ô∏è‚É£ Scraping √©tendu des valeurs nutritionnelles sur Ciqual.
        3Ô∏è‚É£ Sauvegarde finale dans un fichier CSV unique.
    """
    print("üî∏ √âtape 1 : Scraping des ingr√©dients Marmiton...")
    ingredients = scrape_all_ingredients()

    print(f"\nüì¶ {len(ingredients)} ingr√©dients extraits depuis Marmiton.\n")

    print("üî∏ √âtape 2 : Scraping des valeurs nutritionnelles sur Ciqual...")
    scrape_ciqual_extended(ingredients, headless=True)
